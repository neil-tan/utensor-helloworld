/* Auto-generated by utensor cli */
#include "uTensor.h"
#include "params_my_model.hpp"
#include "my_model.hpp"


MyModel::MyModel () :
op_Conv2dOperator_000({ 1, 1, 1, 1 }, VALID)
, op_QuantizeOperator_001()
, op_FullyConnectedOperator_002(TFLM::TfLiteFusedActivation::kTfLiteActNone)
, op_DequantizeOperator_003()
, op_ReshapeOperator_004({ 1, 288 })
, op_ReLUOperator_005()
, op_MaxPoolOperator_006()
, op_FullyConnectedOperator_007(TFLM::TfLiteFusedActivation::kTfLiteActRelu)
{
  Context::get_default_context()->set_ram_data_allocator(&ram_allocator);
  Context::get_default_context()->set_metadata_allocator(&metadata_allocator);
  // TODO: moving ROMTensor declarations here
}

void MyModel::compute()
{
  // update context in case there are multiple models being run
  Context::get_default_context()->set_ram_data_allocator(&ram_allocator);
  Context::get_default_context()->set_metadata_allocator(&metadata_allocator);
  // start rendering local snippets
  Tensor t_tfl.quantize0 = new RamTensor({ 1, 28, 28, 1 }, i8);
    int32_t t_tfl.quantize0_zp = -128;
    float t_tfl.quantize0_scale = 0.003921569;
    PerTensorQuantizationParams t_tfl.quantize0_quant_params(t_tfl.quantize0_zp, t_tfl.quantize0_scale);
    t_tfl.quantize0->set_quantization_params(t_tfl.quantize0_quant_params);


  op_QuantizeOperator_001
    .set_inputs({
        { TflmSymQuantOps::QuantizeOperator<int8_t, float>::input, inputs[input_0].tensor() },
    })
    .set_outputs({
        { TflmSymQuantOps::QuantizeOperator<int8_t, float>::output, t_tfl.quantize0}
    })
    .eval();

  Tensor t_my_modelmax_pooling2dMaxPool0 = new RamTensor({ 1, 14, 14, 1 }, i8);
    int32_t t_my_modelmax_pooling2dMaxPool0_zp = -128;
    float t_my_modelmax_pooling2dMaxPool0_scale = 0.003921569;
    PerTensorQuantizationParams t_my_modelmax_pooling2dMaxPool0_quant_params(t_my_modelmax_pooling2dMaxPool0_zp, t_my_modelmax_pooling2dMaxPool0_scale);
    t_my_modelmax_pooling2dMaxPool0->set_quantization_params(t_my_modelmax_pooling2dMaxPool0_quant_params);


  op_MaxPoolOperator_006
    .set_inputs({
        { ReferenceOperators::MaxPoolOperator<int8_t>::in, t_tfl.quantize0 },
    })
    .set_outputs({
        { ReferenceOperators::MaxPoolOperator<int8_t>::out, t_my_modelmax_pooling2dMaxPool0}
    })
    .eval();

  t_tfl.quantize0.free();

  Tensor t_my_modelconv2dConv2D0 = new RomTensor({ 8, 3, 3, 1 }, i8, data_my_model_conv2d_Conv2D_0);
    int32_t arr_t_my_modelconv2dConv2D0_zp[8] = { 0, 0, 0, 0, 0, 0, 0, 0 };
    float arr_t_my_modelconv2dConv2D0_scale[8] = { 0.009057076, 0.005483946, 0.005092647, 0.0120434575, 0.008175018, 0.0064260387, 0.009051534, 0.010015487 };
    PerChannelQuantizationParams t_my_modelconv2dConv2D0_quant_params(arr_t_my_modelconv2dConv2D0_zp, arr_t_my_modelconv2dConv2D0_scale);
    t_my_modelconv2dConv2D0->set_quantization_params(t_my_modelconv2dConv2D0_quant_params);


  Tensor t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0 = new RomTensor({ 8 }, i32, data_my_model_conv2d_BiasAdd__my_model_conv2d_Conv2D__my_model_conv2d_bias_0);
    int32_t arr_t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_zp[8] = { 0, 0, 0, 0, 0, 0, 0, 0 };
    float arr_t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_scale[8] = { 3.5517947e-05, 2.1505672e-05, 1.9971165e-05, 4.722925e-05, 3.2058895e-05, 2.5200154e-05, 3.5496214e-05, 3.927642e-05 };
    PerChannelQuantizationParams t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_quant_params(arr_t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_zp, arr_t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_scale);
    t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0->set_quantization_params(t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_quant_params);


  Tensor t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0 = new RamTensor({ 1, 12, 12, 8 }, i8);
    int32_t t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_zp = -128;
    float t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_scale = 0.011082776;
    PerTensorQuantizationParams t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_quant_params(t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_zp, t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_scale);
    t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0->set_quantization_params(t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0_quant_params);


  op_Conv2dOperator_000
    .set_inputs({
        { ReferenceOperators::Conv2dOperator<int8_t>::in, t_my_modelmax_pooling2dMaxPool0 },
        { ReferenceOperators::Conv2dOperator<int8_t>::filter, t_my_modelconv2dConv2D0 },
    })
    .set_outputs({
        { ReferenceOperators::Conv2dOperator<int8_t>::out, t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0}
    })
    .eval();

  t_my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0.free();

  t_my_modelmax_pooling2dMaxPool0.free();

  t_my_modelconv2dConv2D0.free();

  Tensor t_2_CONV_2DReLU0 = new RamTensor({ 1, 12, 12, 8 }, i8);
    int32_t t_2_CONV_2DReLU0_zp = -128;
    float t_2_CONV_2DReLU0_scale = 0.011082776;
    PerTensorQuantizationParams t_2_CONV_2DReLU0_quant_params(t_2_CONV_2DReLU0_zp, t_2_CONV_2DReLU0_scale);
    t_2_CONV_2DReLU0->set_quantization_params(t_2_CONV_2DReLU0_quant_params);


  op_ReLUOperator_005
    .set_inputs({
        { ReferenceOperators::ReLUOperator<int8_t>::in, t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0 },
    })
    .set_outputs({
        { ReferenceOperators::ReLUOperator<int8_t>::out, t_2_CONV_2DReLU0}
    })
    .eval();

  t_my_modelconv2dRelu__my_modelconv2dBiasAdd__my_modelconv2dConv2D__my_modelconv2dbias0.free();

  Tensor t_my_modelmax_pooling2dMaxPool_10 = new RamTensor({ 1, 6, 6, 8 }, i8);
    int32_t t_my_modelmax_pooling2dMaxPool_10_zp = -128;
    float t_my_modelmax_pooling2dMaxPool_10_scale = 0.011082776;
    PerTensorQuantizationParams t_my_modelmax_pooling2dMaxPool_10_quant_params(t_my_modelmax_pooling2dMaxPool_10_zp, t_my_modelmax_pooling2dMaxPool_10_scale);
    t_my_modelmax_pooling2dMaxPool_10->set_quantization_params(t_my_modelmax_pooling2dMaxPool_10_quant_params);


  op_MaxPoolOperator_006
    .set_inputs({
        { ReferenceOperators::MaxPoolOperator<int8_t>::in, t_2_CONV_2DReLU0 },
    })
    .set_outputs({
        { ReferenceOperators::MaxPoolOperator<int8_t>::out, t_my_modelmax_pooling2dMaxPool_10}
    })
    .eval();

  t_2_CONV_2DReLU0.free();

  Tensor t_my_modelflattenReshape0 = new RamTensor({ 1, 288 }, i8);
    int32_t t_my_modelflattenReshape0_zp = -128;
    float t_my_modelflattenReshape0_scale = 0.011082776;
    PerTensorQuantizationParams t_my_modelflattenReshape0_quant_params(t_my_modelflattenReshape0_zp, t_my_modelflattenReshape0_scale);
    t_my_modelflattenReshape0->set_quantization_params(t_my_modelflattenReshape0_quant_params);


  op_ReshapeOperator_004
    .set_inputs({
        { ReferenceOperators::ReshapeOperator<int8_t>::input, t_my_modelmax_pooling2dMaxPool_10 },
    })
    .set_outputs({
        { ReferenceOperators::ReshapeOperator<int8_t>::output, t_my_modelflattenReshape0}
    })
    .eval();

  t_my_modelmax_pooling2dMaxPool_10.free();

  Tensor t_my_modeldenseMatMul0 = new RomTensor({ 288, 16 }, i8, data_my_model_dense_MatMul_0);
    int32_t t_my_modeldenseMatMul0_zp = 0;
    float t_my_modeldenseMatMul0_scale = 0.012238176;
    PerTensorQuantizationParams t_my_modeldenseMatMul0_quant_params(t_my_modeldenseMatMul0_zp, t_my_modeldenseMatMul0_scale);
    t_my_modeldenseMatMul0->set_quantization_params(t_my_modeldenseMatMul0_quant_params);


  Tensor t_my_modeldensebias0 = new RomTensor({ 16 }, i32, data_my_model_dense_bias_0);
    int32_t t_my_modeldensebias0_zp = 0;
    float t_my_modeldensebias0_scale = 0.00013563296;
    PerTensorQuantizationParams t_my_modeldensebias0_quant_params(t_my_modeldensebias0_zp, t_my_modeldensebias0_scale);
    t_my_modeldensebias0->set_quantization_params(t_my_modeldensebias0_quant_params);


  Tensor t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0 = new RamTensor({ 1, 16 }, i8);
    int32_t t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0_zp = -128;
    float t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0_scale = 0.08757848;
    PerTensorQuantizationParams t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0_quant_params(t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0_zp, t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0_scale);
    t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0->set_quantization_params(t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0_quant_params);


  op_FullyConnectedOperator_007
    .set_inputs({
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::input, t_my_modelflattenReshape0 },
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::filter, t_my_modeldenseMatMul0 },
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::bias, t_my_modeldensebias0 },
    })
    .set_outputs({
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::output, t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0}
    })
    .eval();

  t_my_modeldenseMatMul0.free();

  t_my_modeldensebias0.free();

  t_my_modelflattenReshape0.free();

  Tensor t_my_modeldense_1MatMul0 = new RomTensor({ 16, 10 }, i8, data_my_model_dense_1_MatMul_0);
    int32_t t_my_modeldense_1MatMul0_zp = 0;
    float t_my_modeldense_1MatMul0_scale = 0.010260945;
    PerTensorQuantizationParams t_my_modeldense_1MatMul0_quant_params(t_my_modeldense_1MatMul0_zp, t_my_modeldense_1MatMul0_scale);
    t_my_modeldense_1MatMul0->set_quantization_params(t_my_modeldense_1MatMul0_quant_params);


  Tensor t_my_modeldense_1bias0 = new RomTensor({ 10 }, i32, data_my_model_dense_1_bias_0);
    int32_t t_my_modeldense_1bias0_zp = 0;
    float t_my_modeldense_1bias0_scale = 0.00089863804;
    PerTensorQuantizationParams t_my_modeldense_1bias0_quant_params(t_my_modeldense_1bias0_zp, t_my_modeldense_1bias0_scale);
    t_my_modeldense_1bias0->set_quantization_params(t_my_modeldense_1bias0_quant_params);


  Tensor t_StatefulPartitionedCall010 = new RamTensor({ 1, 10 }, i8);
    int32_t t_StatefulPartitionedCall010_zp = 12;
    float t_StatefulPartitionedCall010_scale = 0.17513473;
    PerTensorQuantizationParams t_StatefulPartitionedCall010_quant_params(t_StatefulPartitionedCall010_zp, t_StatefulPartitionedCall010_scale);
    t_StatefulPartitionedCall010->set_quantization_params(t_StatefulPartitionedCall010_quant_params);


  op_FullyConnectedOperator_002
    .set_inputs({
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::input, t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0 },
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::filter, t_my_modeldense_1MatMul0 },
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::bias, t_my_modeldense_1bias0 },
    })
    .set_outputs({
        { TflmSymQuantOps::FullyConnectedOperator<int8_t>::output, t_StatefulPartitionedCall010}
    })
    .eval();

  t_my_modeldenseMatMul__my_modeldenseBiasAdd__my_modeldenseRelu0.free();

  t_my_modeldense_1bias0.free();

  t_my_modeldense_1MatMul0.free();

  op_DequantizeOperator_003
    .set_inputs({
        { TflmSymQuantOps::DequantizeOperator<float, int8_t>::a, t_StatefulPartitionedCall010 },
    })
    .set_outputs({
        { TflmSymQuantOps::DequantizeOperator<float, int8_t>::b, outputs[output_0].tensor()}
    })
    .eval();

  t_StatefulPartitionedCall010.free();
  // end of rendering local snippets
}